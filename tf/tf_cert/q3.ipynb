{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# image files. There are 43 unique classes in total. The images are of shape\n",
    "# (30,30,3).\n",
    "# ==============================================================================\n",
    "\n",
    "# HINT: Your neural network must have a validation accuracy of approximately\n",
    "# 0.95 or above on the normalized validation dataset for top marks.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import zipfile\n",
    " \n",
    "import tensorflow as tf\n",
    " \n",
    "# This function downloads and extracts the dataset to the directory that\n",
    "# contains this file.\n",
    "# DO NOT CHANGE THIS CODE\n",
    "# (unless you need to change https to http)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "def download_and_extract_data():\n",
    "   url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/germantrafficsigns.zip'\n",
    "   wget.download(url)\n",
    "   #urllib.request.urlretrieve(url, 'germantrafficsigns.zip')\n",
    "   with zipfile.ZipFile('germantrafficsigns.zip', 'r') as zip_ref:\n",
    "       zip_ref.extractall()\n",
    "down_file = download_and_extract_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "43\n",
      "['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009']\n"
     ]
    }
   ],
   "source": [
    " # COMPLETE THE CODE IN THIS FUNCTION\n",
    "def preprocess(image, label):\n",
    "   # NORMALIZE YOUR IMAGES HERE (HINT: Rescale by 1/.255)\n",
    "   image = image /255\n",
    "   labelZip = label\n",
    "   return image, labelZip\n",
    " \n",
    " \n",
    "# This function loads the data, normalizes and resizes the images, splits it into\n",
    "# train and validation sets, defines the model, compiles it and finally\n",
    "# trains the model. The trained model is returned from this function.\n",
    "import os\n",
    "base_dir = \"./\"\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "train_fname = os.listdir(train_dir)\n",
    "val_fname = os.listdir(val_dir)\n",
    "print(len(train_fname))\n",
    "print(len(val_fname))\n",
    "print(train_fname[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# COMPLETE THE CODE IN THIS FUNCTION.\n",
    "def solution_model(train_dir, val_dir):\n",
    "   # Downloads and extracts the dataset to the directory that\n",
    "   # contains this file.\n",
    "      \n",
    "   # download_and_extract_data()\n",
    " \n",
    "   BATCH_SIZE = 32\n",
    "   IMG_SIZE = 30\n",
    " \n",
    "   # The following code reads the training and validation data from their\n",
    "   # respective directories, resizes them into the specified image size\n",
    "   # and splits them into batches. You must fill in the image_size\n",
    "   # argument for both training and validation data.\n",
    "   # HINT: Image size is a tuple\n",
    "   train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "       directory=train_dir,\n",
    "       label_mode='categorical',\n",
    "       image_size=  (30, 30),\n",
    "       batch_size = BATCH_SIZE)\n",
    " \n",
    "   val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "       directory=val_dir,\n",
    "       label_mode='categorical',\n",
    "       image_size= (30, 30),\n",
    "       batch_size = BATCH_SIZE,)\n",
    "   \n",
    "   return train_ds, val_ds\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31367 files belonging to 43 classes.\n",
      "Found 7842 files belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = solution_model(train_dir, val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   # Normalizes train and validation datasets using the\n",
    "   # preprocess() function.\n",
    "   # Also makes other calls, as evident from the code, to prepare them for\n",
    "   # training.\n",
    "   # Do not batch or resize the images in the dataset here since it's already\n",
    "   # been done previously.\n",
    "def img_process(train_ds, val_ds):\n",
    "        train_img = train_ds.map(\n",
    "            preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(\n",
    "            tf.data.experimental.AUTOTUNE)\n",
    "        val_img = val_ds.map(\n",
    "            preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "        return train_img, val_img\n",
    "\n",
    "train_img, val_img = img_process(train_ds, val_ds)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               6423040   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 43)                22059     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,446,891\n",
      "Trainable params: 6,446,891\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Code to define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    # ADD LAYERS OF THE MODEL HERE\n",
    "\n",
    "    # If you don't adhere to the instructions in the following comments,\n",
    "    # tests will fail to grade your model:\n",
    "    # The input layer of your model must have an input shape of\n",
    "    # (30,30,3).\n",
    "    # Make sure your last layer has 43 neurons activated by softmax.\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(30, 30, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(43, activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "981/981 [==============================] - 37s 37ms/step - loss: 0.7727 - accuracy: 0.7968\n",
      "Epoch 2/10\n",
      "981/981 [==============================] - 33s 34ms/step - loss: 0.1725 - accuracy: 0.9552\n",
      "Epoch 3/10\n",
      "981/981 [==============================] - 33s 34ms/step - loss: 0.0989 - accuracy: 0.9740\n",
      "Epoch 4/10\n",
      "981/981 [==============================] - 33s 33ms/step - loss: 0.0783 - accuracy: 0.9794\n",
      "Epoch 5/10\n",
      "981/981 [==============================] - 33s 34ms/step - loss: 0.0608 - accuracy: 0.9834\n",
      "Epoch 6/10\n",
      "981/981 [==============================] - 33s 34ms/step - loss: 0.0437 - accuracy: 0.9887\n",
      "Epoch 7/10\n",
      "981/981 [==============================] - 33s 34ms/step - loss: 0.0407 - accuracy: 0.9899\n",
      "Epoch 8/10\n",
      "981/981 [==============================] - 33s 34ms/step - loss: 0.0383 - accuracy: 0.9907\n",
      "Epoch 9/10\n",
      "981/981 [==============================] - 33s 33ms/step - loss: 0.0422 - accuracy: 0.9898\n",
      "Epoch 10/10\n",
      "981/981 [==============================] - 33s 34ms/step - loss: 0.0237 - accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b3aa0ada90>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to compile and train the model\n",
    "model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(train_img, epochs = 10)\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that you'll need to save your model as a .h5 like this.\n",
    "# When you press the Submit and Test button, your saved .h5 model will\n",
    "# be sent to the testing infrastructure for scoring\n",
    "# and the score will be returned to you.\n",
    "'''if __name__ == '__main__':\n",
    "   model = solution_model()\n",
    "   model.save(\"mymodel.h5\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mymodelq3.h5\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "54409eae9e1c57883ccd4f88707ee2e01c9055555e7b97a265283b72fed450ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
