{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# image files. There are 43 unique classes in total. The images are of shape\n",
    "# (30,30,3).\n",
    "# ==============================================================================\n",
    "\n",
    "# HINT: Your neural network must have a validation accuracy of approximately\n",
    "# 0.95 or above on the normalized validation dataset for top marks.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import zipfile\n",
    " \n",
    "import tensorflow as tf\n",
    " \n",
    "# This function downloads and extracts the dataset to the directory that\n",
    "# contains this file.\n",
    "# DO NOT CHANGE THIS CODE\n",
    "# (unless you need to change https to http)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import pathlib\n",
    "def download_and_extract_data():\n",
    "    file1 = pathlib.Path(\"germantrafficsigns.zip\")\n",
    "    file2 = pathlib.Path(\"germantrafficsigns.zip\")\n",
    "    if file2.exists ():\n",
    "        print(\"\") #(\"CSV file exist\")\n",
    "    elif file1.exists():\n",
    "        print(\"Zip file exist\")\n",
    "        with zipfile.ZipFile('germantrafficsigns.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall()    \n",
    "    else:\n",
    "        wget.download('https://storage.googleapis.com/download.tensorflow.org/data/certificate/germantrafficsigns.zip')\n",
    "        with zipfile.ZipFile('germantrafficsigns.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall()\n",
    "down_file = download_and_extract_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "43\n",
      "['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009']\n"
     ]
    }
   ],
   "source": [
    " # COMPLETE THE CODE IN THIS FUNCTION\n",
    "def preprocess(image, label):\n",
    "   # NORMALIZE YOUR IMAGES HERE (HINT: Rescale by 1/.255)\n",
    "   image = image /255\n",
    "   labelZip = label\n",
    "   return image, labelZip\n",
    " \n",
    " \n",
    "# This function loads the data, normalizes and resizes the images, splits it into\n",
    "# train and validation sets, defines the model, compiles it and finally\n",
    "# trains the model. The trained model is returned from this function.\n",
    "import os\n",
    "base_dir = \"./\"\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "train_fname = os.listdir(train_dir)\n",
    "val_fname = os.listdir(val_dir)\n",
    "print(len(train_fname))\n",
    "print(len(val_fname))\n",
    "print(train_fname[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# COMPLETE THE CODE IN THIS FUNCTION.\n",
    "def solution_model(train_dir, val_dir):\n",
    "   # Downloads and extracts the dataset to the directory that\n",
    "   # contains this file.\n",
    "      \n",
    "   # download_and_extract_data()\n",
    " \n",
    "   BATCH_SIZE = 32\n",
    "   IMG_SIZE = 30\n",
    " \n",
    "   # The following code reads the training and validation data from their\n",
    "   # respective directories, resizes them into the specified image size\n",
    "   # and splits them into batches. You must fill in the image_size\n",
    "   # argument for both training and validation data.\n",
    "   # HINT: Image size is a tuple\n",
    "   train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "       directory=train_dir,\n",
    "       label_mode='categorical',\n",
    "       image_size=  (30, 30),\n",
    "       batch_size = BATCH_SIZE)\n",
    " \n",
    "   val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "       directory=val_dir,\n",
    "       label_mode='categorical',\n",
    "       image_size= (30, 30),\n",
    "       batch_size = BATCH_SIZE,)\n",
    "   \n",
    "   return train_ds, val_ds\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31367 files belonging to 43 classes.\n",
      "Found 7842 files belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = solution_model(train_dir, val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   # Normalizes train and validation datasets using the\n",
    "   # preprocess() function.\n",
    "   # Also makes other calls, as evident from the code, to prepare them for\n",
    "   # training.\n",
    "   # Do not batch or resize the images in the dataset here since it's already\n",
    "   # been done previously.\n",
    "def img_process(train_ds, val_ds):\n",
    "        train_img = train_ds.map(\n",
    "            preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(\n",
    "            tf.data.experimental.AUTOTUNE)\n",
    "        val_img = val_ds.map(\n",
    "            preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "        return train_img, val_img\n",
    "\n",
    "train_img, val_img = img_process(train_ds, val_ds)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 43)                22059     \n",
      "=================================================================\n",
      "Total params: 1,240,939\n",
      "Trainable params: 1,240,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Code to define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    # ADD LAYERS OF THE MODEL HERE\n",
    "\n",
    "    # If you don't adhere to the instructions in the following comments,\n",
    "    # tests will fail to grade your model:\n",
    "    # The input layer of your model must have an input shape of\n",
    "    # (30,30,3).\n",
    "    # Make sure your last layer has 43 neurons activated by softmax.\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(30, 30, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(43, activation='softmax')\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    # Check accuracy\n",
    "    if(logs.get('accuracy') > 0.95):\n",
    "\n",
    "      # Stop if threshold is met\n",
    "      print(\"\\nLoss is more than 0.95 so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "# Instantiate class\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 6s 536ms/step - loss: 3.7072 - accuracy: 0.0547 - val_loss: 3.5988 - val_accuracy: 0.0742\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 1s 197ms/step - loss: 3.5734 - accuracy: 0.0664 - val_loss: 3.5541 - val_accuracy: 0.1172\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 1s 183ms/step - loss: 3.4856 - accuracy: 0.1133 - val_loss: 3.4644 - val_accuracy: 0.0977\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 1s 190ms/step - loss: 3.3678 - accuracy: 0.1172 - val_loss: 3.3609 - val_accuracy: 0.1094\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 3.2383 - accuracy: 0.1562 - val_loss: 3.3345 - val_accuracy: 0.1406\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 3.2502 - accuracy: 0.1328 - val_loss: 3.1522 - val_accuracy: 0.1680\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 3.0006 - accuracy: 0.1602 - val_loss: 2.9706 - val_accuracy: 0.2578\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 3.0050 - accuracy: 0.3047 - val_loss: 2.9017 - val_accuracy: 0.3242\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 2.6822 - accuracy: 0.3164 - val_loss: 2.8172 - val_accuracy: 0.3086\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 2.9095 - accuracy: 0.2617 - val_loss: 2.7235 - val_accuracy: 0.3398\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 2s 249ms/step - loss: 2.5658 - accuracy: 0.3633 - val_loss: 2.6308 - val_accuracy: 0.3086\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 2.4763 - accuracy: 0.3594 - val_loss: 2.3246 - val_accuracy: 0.4180\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 1s 190ms/step - loss: 2.3983 - accuracy: 0.3398 - val_loss: 2.2486 - val_accuracy: 0.3906\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 2.3506 - accuracy: 0.3359 - val_loss: 2.2856 - val_accuracy: 0.3711\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 1s 192ms/step - loss: 1.9915 - accuracy: 0.4531 - val_loss: 2.1739 - val_accuracy: 0.4531\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 1s 189ms/step - loss: 2.0372 - accuracy: 0.4727 - val_loss: 2.0037 - val_accuracy: 0.4414\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 1s 189ms/step - loss: 1.9848 - accuracy: 0.4883 - val_loss: 1.8501 - val_accuracy: 0.4883\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 1s 200ms/step - loss: 1.9784 - accuracy: 0.4805 - val_loss: 1.9524 - val_accuracy: 0.4844\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 1s 192ms/step - loss: 1.7110 - accuracy: 0.5273 - val_loss: 1.8339 - val_accuracy: 0.4727\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 1s 195ms/step - loss: 1.6242 - accuracy: 0.4961 - val_loss: 1.7268 - val_accuracy: 0.5156\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 1.6582 - accuracy: 0.5195 - val_loss: 1.4728 - val_accuracy: 0.5703\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 1.5339 - accuracy: 0.5352 - val_loss: 1.6348 - val_accuracy: 0.5156\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 2s 303ms/step - loss: 1.5169 - accuracy: 0.5508 - val_loss: 1.4707 - val_accuracy: 0.5664\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 2s 264ms/step - loss: 1.2209 - accuracy: 0.6367 - val_loss: 1.4492 - val_accuracy: 0.5938\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 1.3169 - accuracy: 0.6484 - val_loss: 1.3668 - val_accuracy: 0.6484\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 1s 196ms/step - loss: 1.2697 - accuracy: 0.6250 - val_loss: 1.3488 - val_accuracy: 0.6133\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 2s 257ms/step - loss: 1.3561 - accuracy: 0.6055 - val_loss: 1.2658 - val_accuracy: 0.6406\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 1.2357 - accuracy: 0.6367 - val_loss: 1.2953 - val_accuracy: 0.6523\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 2s 322ms/step - loss: 1.1710 - accuracy: 0.6719 - val_loss: 1.0981 - val_accuracy: 0.6953\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 2s 324ms/step - loss: 1.1834 - accuracy: 0.6797 - val_loss: 1.0596 - val_accuracy: 0.6875\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 2s 319ms/step - loss: 0.9217 - accuracy: 0.7539 - val_loss: 1.1023 - val_accuracy: 0.6562\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 2s 284ms/step - loss: 1.1306 - accuracy: 0.6758 - val_loss: 0.9978 - val_accuracy: 0.7383\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 2s 289ms/step - loss: 0.8441 - accuracy: 0.7500 - val_loss: 1.0063 - val_accuracy: 0.6953\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 3s 343ms/step - loss: 0.9721 - accuracy: 0.7148 - val_loss: 0.9394 - val_accuracy: 0.7461\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 2s 295ms/step - loss: 0.7939 - accuracy: 0.7812 - val_loss: 0.8847 - val_accuracy: 0.7305\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 2s 305ms/step - loss: 0.8292 - accuracy: 0.7656 - val_loss: 0.9311 - val_accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 2s 316ms/step - loss: 0.7574 - accuracy: 0.7812 - val_loss: 0.7622 - val_accuracy: 0.7891\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 2s 311ms/step - loss: 0.7846 - accuracy: 0.7812 - val_loss: 0.8457 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 2s 289ms/step - loss: 0.7810 - accuracy: 0.7812 - val_loss: 0.8287 - val_accuracy: 0.7969\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 2s 300ms/step - loss: 0.7848 - accuracy: 0.7656 - val_loss: 0.7509 - val_accuracy: 0.7812\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 2s 290ms/step - loss: 0.5872 - accuracy: 0.8633 - val_loss: 0.7579 - val_accuracy: 0.7969\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 2s 302ms/step - loss: 0.7793 - accuracy: 0.7930 - val_loss: 0.7068 - val_accuracy: 0.8281\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 2s 307ms/step - loss: 0.5999 - accuracy: 0.8438 - val_loss: 0.6793 - val_accuracy: 0.8086\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 2s 278ms/step - loss: 0.6022 - accuracy: 0.8164 - val_loss: 0.7027 - val_accuracy: 0.7969\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 2s 304ms/step - loss: 0.7122 - accuracy: 0.7695 - val_loss: 0.6165 - val_accuracy: 0.8281\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 2s 341ms/step - loss: 0.7245 - accuracy: 0.7891 - val_loss: 0.6750 - val_accuracy: 0.8281\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 2s 269ms/step - loss: 0.6797 - accuracy: 0.8164 - val_loss: 0.7012 - val_accuracy: 0.7930\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 2s 292ms/step - loss: 0.5591 - accuracy: 0.8516 - val_loss: 0.6482 - val_accuracy: 0.8125\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 2s 334ms/step - loss: 0.5829 - accuracy: 0.8281 - val_loss: 0.5059 - val_accuracy: 0.8281\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 2s 288ms/step - loss: 0.4967 - accuracy: 0.8672 - val_loss: 0.5244 - val_accuracy: 0.8555\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 2s 277ms/step - loss: 0.4976 - accuracy: 0.8672 - val_loss: 0.5154 - val_accuracy: 0.8594\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 2s 303ms/step - loss: 0.5693 - accuracy: 0.8711 - val_loss: 0.4543 - val_accuracy: 0.8711\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 2s 289ms/step - loss: 0.3759 - accuracy: 0.9062 - val_loss: 0.5341 - val_accuracy: 0.8633\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 2s 292ms/step - loss: 0.4905 - accuracy: 0.8672 - val_loss: 0.6283 - val_accuracy: 0.8203\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 2s 295ms/step - loss: 0.5104 - accuracy: 0.8516 - val_loss: 0.5251 - val_accuracy: 0.8711\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 2s 290ms/step - loss: 0.5124 - accuracy: 0.8359 - val_loss: 0.4807 - val_accuracy: 0.8516\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 2s 321ms/step - loss: 0.4441 - accuracy: 0.8828 - val_loss: 0.5227 - val_accuracy: 0.8359\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 2s 308ms/step - loss: 0.4456 - accuracy: 0.8633 - val_loss: 0.4821 - val_accuracy: 0.8594\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 2s 285ms/step - loss: 0.4317 - accuracy: 0.8789 - val_loss: 0.4449 - val_accuracy: 0.8789\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 2s 293ms/step - loss: 0.5069 - accuracy: 0.8594 - val_loss: 0.3963 - val_accuracy: 0.8867\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 2s 300ms/step - loss: 0.4151 - accuracy: 0.8828 - val_loss: 0.4551 - val_accuracy: 0.8711\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 2s 321ms/step - loss: 0.3859 - accuracy: 0.9102 - val_loss: 0.4853 - val_accuracy: 0.8789\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 2s 281ms/step - loss: 0.4247 - accuracy: 0.8867 - val_loss: 0.4118 - val_accuracy: 0.8633\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 2s 322ms/step - loss: 0.4571 - accuracy: 0.8711 - val_loss: 0.3842 - val_accuracy: 0.9141\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 2s 295ms/step - loss: 0.3582 - accuracy: 0.9141 - val_loss: 0.3719 - val_accuracy: 0.9219\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 2s 297ms/step - loss: 0.4426 - accuracy: 0.8438 - val_loss: 0.3680 - val_accuracy: 0.9102\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 2s 317ms/step - loss: 0.2871 - accuracy: 0.9141 - val_loss: 0.3951 - val_accuracy: 0.8867\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 2s 289ms/step - loss: 0.3599 - accuracy: 0.9219 - val_loss: 0.3837 - val_accuracy: 0.8945\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 2s 300ms/step - loss: 0.3256 - accuracy: 0.9062 - val_loss: 0.3816 - val_accuracy: 0.8984\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 3s 346ms/step - loss: 0.4265 - accuracy: 0.8906 - val_loss: 0.3713 - val_accuracy: 0.8945\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 2s 323ms/step - loss: 0.3759 - accuracy: 0.8672 - val_loss: 0.5497 - val_accuracy: 0.8125\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 2s 306ms/step - loss: 0.5063 - accuracy: 0.8555 - val_loss: 0.3830 - val_accuracy: 0.8906\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 2s 323ms/step - loss: 0.3480 - accuracy: 0.8750 - val_loss: 0.3713 - val_accuracy: 0.9102\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.3869 - accuracy: 0.8906 - val_loss: 0.2706 - val_accuracy: 0.9219\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 2s 310ms/step - loss: 0.3071 - accuracy: 0.9258 - val_loss: 0.2684 - val_accuracy: 0.9375\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 2s 326ms/step - loss: 0.2622 - accuracy: 0.9219 - val_loss: 0.2821 - val_accuracy: 0.9375\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.2545 - accuracy: 0.9336 - val_loss: 0.3238 - val_accuracy: 0.8906\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 2s 312ms/step - loss: 0.2452 - accuracy: 0.9336 - val_loss: 0.3428 - val_accuracy: 0.8906\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 2s 315ms/step - loss: 0.3180 - accuracy: 0.8906 - val_loss: 0.3389 - val_accuracy: 0.9258\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.2540 - accuracy: 0.9258 - val_loss: 0.3731 - val_accuracy: 0.9062\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 2s 315ms/step - loss: 0.2274 - accuracy: 0.9414 - val_loss: 0.3255 - val_accuracy: 0.9062\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 2s 313ms/step - loss: 0.2258 - accuracy: 0.9297 - val_loss: 0.2636 - val_accuracy: 0.9258\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 2s 307ms/step - loss: 0.3699 - accuracy: 0.8945 - val_loss: 0.2554 - val_accuracy: 0.9336\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 2s 307ms/step - loss: 0.3805 - accuracy: 0.8672 - val_loss: 0.2770 - val_accuracy: 0.9141\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 2s 304ms/step - loss: 0.3264 - accuracy: 0.9180 - val_loss: 0.2549 - val_accuracy: 0.9297\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 3s 405ms/step - loss: 0.3619 - accuracy: 0.8867 - val_loss: 0.3364 - val_accuracy: 0.9141\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 3s 458ms/step - loss: 0.3084 - accuracy: 0.9141 - val_loss: 0.3470 - val_accuracy: 0.8945\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 2s 336ms/step - loss: 0.3067 - accuracy: 0.9141 - val_loss: 0.2410 - val_accuracy: 0.9258\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 3s 360ms/step - loss: 0.1994 - accuracy: 0.9609 - val_loss: 0.2587 - val_accuracy: 0.9414\n",
      "\n",
      "Loss is more than 0.95 so cancelling training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2742e07bb80>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to compile and train the model\n",
    "model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(train_img,\n",
    "          steps_per_epoch=8,  \n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data = val_img,\n",
    "          validation_steps=8,\n",
    "          callbacks=[callbacks])\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that you'll need to save your model as a .h5 like this.\n",
    "# When you press the Submit and Test button, your saved .h5 model will\n",
    "# be sent to the testing infrastructure for scoring\n",
    "# and the score will be returned to you.\n",
    "'''if __name__ == '__main__':\n",
    "   model = solution_model()\n",
    "   model.save(\"mymodel.h5\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mymodelq3.h5\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
