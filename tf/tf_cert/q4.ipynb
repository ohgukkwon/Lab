{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "8FlNKcdnIeAp",
        "outputId": "7403359c-4417-42b8-ab15-75c4cd756e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "file exist\n"
          ]
        }
      ],
      "source": [
        "'''import pathlib\n",
        "file = pathlib.Path(\"sarcasm.json\")\n",
        "if file.exists ():\n",
        "  print(\"file exist\")    \n",
        "else:\n",
        "  !wget https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json\n",
        "#urllib.request.urlretrieve(url, 'sarcasm.json')\n",
        "'''\n",
        "\n",
        "import wget\n",
        "\n",
        "import pathlib\n",
        "file = pathlib.Path(\"sarcasm.json\")\n",
        "if file.exists ():\n",
        "  print(\"file exist\")    \n",
        "else:\n",
        "  wget.download('https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2mE-vOTAKueV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "c:\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
            "c:\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import json\n",
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "#from scipy.stats import linregress\n",
        "\n",
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000\n",
        "\n",
        "lstm_dim = 32\n",
        "dense_dim = 24\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kn_VWWqaK30K"
      },
      "outputs": [],
      "source": [
        "def solution_model(json_file):\n",
        "\n",
        "  #url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\n",
        "  #urllib.request.urlretrieve(url, 'sarcasm.json')\n",
        "\n",
        "  # DO NOT CHANGE THIS CODE OR THE TESTS MAY NOT WORK\n",
        "  sentences = []\n",
        "  labels = []\n",
        "  # YOUR CODE HERE\n",
        "  with open(json_file, 'r') as f:\n",
        "      datastore = json.load(f)\n",
        "\n",
        "  for item in datastore:\n",
        "      sentences.append(item['headline'])\n",
        "      labels.append(item['is_sarcastic'])\n",
        "\n",
        "  return sentences, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5tApReYPM24l"
      },
      "outputs": [],
      "source": [
        "sentences, labels = solution_model('sarcasm.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UyRO8zIVMvCe"
      },
      "outputs": [],
      "source": [
        "\n",
        "def training_data(sentences, labels):\n",
        "\n",
        "  # Split the sentences\n",
        "  training_sentences = sentences[0:training_size]\n",
        "  testing_sentences = sentences[training_size:]\n",
        "\n",
        "  # Split the labels\n",
        "  training_labels = labels[0:training_size]\n",
        "  testing_labels = labels[training_size:]\n",
        "\n",
        "  tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "\n",
        "  # Generate the word index dictionary\n",
        "  tokenizer.fit_on_texts(training_sentences)\n",
        "  word_index = tokenizer.word_index\n",
        "\n",
        "  # Generate and pad the training sequences\n",
        "  training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "  training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "  # Generate and pad the testing sequences\n",
        "  testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "  testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "  training_labels = np.array(training_labels)\n",
        "  testing_labels = np.array(testing_labels)\n",
        "\n",
        "  return training_sentences, training_labels, testing_sentences, testing_labels, training_sequences, training_padded, testing_sequences, testing_padded\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "57v0l9z5Om8q"
      },
      "outputs": [],
      "source": [
        "training_sentences, training_labels, testing_sentences, testing_labels, training_sequences, training_padded, testing_sequences, testing_padded = training_data(sentences, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV0Ab8_CL6sE",
        "outputId": "e25d4e83-8561-42bd-deca-ba86915c03e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "625/625 - 39s - loss: 0.4507 - accuracy: 0.7739 - val_loss: 0.3841 - val_accuracy: 0.8217\n",
            "Epoch 2/40\n",
            "625/625 - 40s - loss: 0.3545 - accuracy: 0.8382 - val_loss: 0.3734 - val_accuracy: 0.8274\n",
            "Epoch 3/40\n",
            "625/625 - 37s - loss: 0.3286 - accuracy: 0.8522 - val_loss: 0.3694 - val_accuracy: 0.8302\n",
            "Epoch 4/40\n",
            "625/625 - 38s - loss: 0.3108 - accuracy: 0.8615 - val_loss: 0.3766 - val_accuracy: 0.8274\n",
            "Epoch 5/40\n",
            "625/625 - 37s - loss: 0.2957 - accuracy: 0.8707 - val_loss: 0.3730 - val_accuracy: 0.8325\n",
            "Epoch 6/40\n",
            "625/625 - 38s - loss: 0.2855 - accuracy: 0.8735 - val_loss: 0.3942 - val_accuracy: 0.8322\n",
            "Epoch 7/40\n",
            "625/625 - 40s - loss: 0.2757 - accuracy: 0.8784 - val_loss: 0.3796 - val_accuracy: 0.8323\n",
            "Epoch 8/40\n",
            "625/625 - 39s - loss: 0.2672 - accuracy: 0.8834 - val_loss: 0.3938 - val_accuracy: 0.8289\n",
            "Epoch 9/40\n",
            "625/625 - 38s - loss: 0.2595 - accuracy: 0.8878 - val_loss: 0.3890 - val_accuracy: 0.8272\n",
            "Epoch 10/40\n",
            "625/625 - 38s - loss: 0.2526 - accuracy: 0.8921 - val_loss: 0.4324 - val_accuracy: 0.8207\n",
            "Epoch 11/40\n",
            "625/625 - 41s - loss: 0.2450 - accuracy: 0.8960 - val_loss: 0.4159 - val_accuracy: 0.8246\n",
            "Epoch 12/40\n",
            "625/625 - 39s - loss: 0.2385 - accuracy: 0.8974 - val_loss: 0.4108 - val_accuracy: 0.8243\n",
            "Epoch 13/40\n",
            "625/625 - 38s - loss: 0.2310 - accuracy: 0.9007 - val_loss: 0.4634 - val_accuracy: 0.8222\n",
            "Epoch 14/40\n",
            "625/625 - 38s - loss: 0.2265 - accuracy: 0.9035 - val_loss: 0.4378 - val_accuracy: 0.8225\n",
            "Epoch 15/40\n",
            "625/625 - 38s - loss: 0.2207 - accuracy: 0.9062 - val_loss: 0.4860 - val_accuracy: 0.8192\n",
            "Epoch 16/40\n",
            "625/625 - 38s - loss: 0.2129 - accuracy: 0.9102 - val_loss: 0.4873 - val_accuracy: 0.8195\n",
            "Epoch 17/40\n",
            "625/625 - 38s - loss: 0.2044 - accuracy: 0.9149 - val_loss: 0.4803 - val_accuracy: 0.8195\n",
            "Epoch 18/40\n",
            "625/625 - 37s - loss: 0.1986 - accuracy: 0.9175 - val_loss: 0.4893 - val_accuracy: 0.8150\n",
            "Epoch 19/40\n",
            "625/625 - 38s - loss: 0.1912 - accuracy: 0.9208 - val_loss: 0.5529 - val_accuracy: 0.8185\n",
            "Epoch 20/40\n",
            "625/625 - 38s - loss: 0.1846 - accuracy: 0.9233 - val_loss: 0.5644 - val_accuracy: 0.8177\n",
            "Epoch 21/40\n",
            "625/625 - 38s - loss: 0.1747 - accuracy: 0.9288 - val_loss: 0.6191 - val_accuracy: 0.8116\n",
            "Epoch 22/40\n",
            "625/625 - 38s - loss: 0.1697 - accuracy: 0.9306 - val_loss: 0.6558 - val_accuracy: 0.8091\n",
            "Epoch 23/40\n",
            "625/625 - 38s - loss: 0.1631 - accuracy: 0.9326 - val_loss: 0.6555 - val_accuracy: 0.8097\n",
            "Epoch 24/40\n",
            "625/625 - 38s - loss: 0.1569 - accuracy: 0.9346 - val_loss: 0.6771 - val_accuracy: 0.8092\n",
            "Epoch 25/40\n",
            "625/625 - 37s - loss: 0.1505 - accuracy: 0.9376 - val_loss: 0.7505 - val_accuracy: 0.8128\n",
            "Epoch 26/40\n",
            "625/625 - 40s - loss: 0.1437 - accuracy: 0.9416 - val_loss: 0.8485 - val_accuracy: 0.8131\n",
            "Epoch 27/40\n",
            "625/625 - 37s - loss: 0.1377 - accuracy: 0.9442 - val_loss: 0.8489 - val_accuracy: 0.8047\n",
            "Epoch 28/40\n",
            "625/625 - 37s - loss: 0.1320 - accuracy: 0.9459 - val_loss: 0.8285 - val_accuracy: 0.8073\n",
            "Epoch 29/40\n",
            "625/625 - 38s - loss: 0.1264 - accuracy: 0.9481 - val_loss: 0.9358 - val_accuracy: 0.8041\n",
            "Epoch 30/40\n",
            "625/625 - 38s - loss: 0.1186 - accuracy: 0.9514 - val_loss: 0.9909 - val_accuracy: 0.8079\n",
            "Epoch 31/40\n",
            "625/625 - 39s - loss: 0.1180 - accuracy: 0.9517 - val_loss: 0.9617 - val_accuracy: 0.8032\n",
            "Epoch 32/40\n",
            "625/625 - 38s - loss: 0.1090 - accuracy: 0.9539 - val_loss: 1.0991 - val_accuracy: 0.8088\n",
            "Epoch 33/40\n",
            "625/625 - 37s - loss: 0.1121 - accuracy: 0.9539 - val_loss: 1.0445 - val_accuracy: 0.8021\n",
            "Epoch 34/40\n",
            "625/625 - 38s - loss: 0.1027 - accuracy: 0.9567 - val_loss: 1.1658 - val_accuracy: 0.8024\n",
            "Epoch 35/40\n",
            "625/625 - 38s - loss: 0.0962 - accuracy: 0.9599 - val_loss: 1.2042 - val_accuracy: 0.7986\n",
            "Epoch 36/40\n",
            "625/625 - 37s - loss: 0.0978 - accuracy: 0.9585 - val_loss: 1.1769 - val_accuracy: 0.7934\n",
            "Epoch 37/40\n",
            "625/625 - 38s - loss: 0.1001 - accuracy: 0.9585 - val_loss: 1.2694 - val_accuracy: 0.8015\n",
            "Epoch 38/40\n",
            "625/625 - 39s - loss: 0.0897 - accuracy: 0.9623 - val_loss: 1.2620 - val_accuracy: 0.8028\n",
            "Epoch 39/40\n",
            "625/625 - 39s - loss: 0.0803 - accuracy: 0.9657 - val_loss: 1.4386 - val_accuracy: 0.7994\n",
            "Epoch 40/40\n",
            "625/625 - 35s - loss: 0.0813 - accuracy: 0.9652 - val_loss: 1.4708 - val_accuracy: 0.7997\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x284c4844b50>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert the labels lists into numpy arrays\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_dim)),\n",
        "    tf.keras.layers.Dense(dense_dim, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_padded, training_labels, epochs=40, validation_data=(testing_padded, testing_labels),\n",
        "          verbose=2)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd7PiVEKNhND"
      },
      "outputs": [],
      "source": [
        "# Note that you'll need to save your model as a .h5 like this.\n",
        "# When you press the Submit and Test button, your saved .h5 model will\n",
        "# be sent to the testing infrastructure for scoring\n",
        "# and the score will be returned to you.\n",
        "'''if __name__ == '__main__':\n",
        "  model = solution_model()\n",
        "  model.save(\"mymodelq4.h5\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVLG3p4KNcfh"
      },
      "outputs": [],
      "source": [
        "model.save(\"mymodelq4.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3 (tags/v3.8.3:6f8c832, May 13 2020, 22:37:02) [MSC v.1924 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
